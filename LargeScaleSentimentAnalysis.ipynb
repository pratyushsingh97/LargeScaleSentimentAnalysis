{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large Scale Sentiment Analysis \n",
    "### by: Pratyush Singh & Mike Volpe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook's purpose is to give you an idea how Mike & I approached and solved the problem using NLU on large amounts of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import requests\n",
    "import urllib.parse\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### If you want to read in your own data, simply replace the 'Twitter_Broadcast Raw Data...' with your own file_name. <br>\n",
    "- Pandas has the ability to read many other types formats such as CSV's. For the full documentation visit the pandas website\n",
    "\n",
    "- https://pandas.pydata.org/pandas-docs/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the files. Replace with the path to your own file. Visit pandas to learn how to read other files\n",
    "q1 = None\n",
    "q2 = None\n",
    "q3 = None\n",
    "q4 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_score, sentiment_label = [], []\n",
    "emotion_score, emotion_label = [], []\n",
    "file_name = None\n",
    "\n",
    "def make_request(row):\n",
    "    \"\"\" This function makes retrieves emotion and sentiment for twitter\n",
    "    \n",
    "    The function makes a call to Watson NLU to retrieve targeted sentiment and\n",
    "    emotion for the word twitter. After the results are retrieved it calls \n",
    "    'process_request' to handle the post-processesing of the json response.\n",
    "    \n",
    "    Args:\n",
    "        - row: the row of data\n",
    "    \n",
    "    Returns: None\n",
    "    \n",
    "    \"\"\"\n",
    "    text = row.Text # replace \"Text\" with the name of the column you wish to analyze\n",
    "    index = row.name\n",
    "    \n",
    "    if not index % 10:\n",
    "        save(file_name)\n",
    "    \n",
    "    # some pre-processesing of the text such as lower-casing and removing punctuation\n",
    "    text = text.strip().lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = str(text)\n",
    "    \n",
    "    try:\n",
    "        if 'twitter' in text:\n",
    "            \n",
    "            # make the actual request to the api with the proper headers\n",
    "            headers = {'Content-Type': 'application/json',}\n",
    "            params = (\n",
    "                    ('text', text),\n",
    "                    ('features','emotion,sentiment'),\n",
    "                    ('entities.emotion', 'true'),\n",
    "                    ('entities.sentiment', 'true'),\n",
    "                    ('emotion.targets', 'twitter'),\n",
    "                    ('sentiment.targets', 'twitter'),\n",
    "                )\n",
    "\n",
    "            response = requests.get(\"https://gateway.watsonplatform.net/natural-language-understanding/api/v1/analyze?version=2019-07-12\", \n",
    "                                     headers=headers, \n",
    "                                     params=params,\n",
    "                                     auth=('apikey', API_KEY))\n",
    "            \n",
    "            response = json.loads(response.text)\n",
    "            \n",
    "            process_request(response)\n",
    "\n",
    "        else:\n",
    "            # if twitter is not in the text, then add this placeholder text to the list\n",
    "            sentiment_label.append('Twitter not in text')\n",
    "            sentiment_score.append(np.inf) \n",
    "\n",
    "            emotion_label.append('Twitter not in text')\n",
    "            emotion_score.append(np.inf)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        # in the case of a keyboard interrupt, save the file and exit the program\n",
    "        print(\"Saving your progress...\")\n",
    "        _save(filename)\n",
    "        \n",
    "        sys.exit()\n",
    "\n",
    "    except Exception as e:\n",
    "        # if any exception has occurred then we add in a filler message\n",
    "        sentiment_label.append(e)\n",
    "        emotion_label.append(e)\n",
    "\n",
    "        sentiment_score.append(np.inf)\n",
    "        emotion_score.append(np.inf)\n",
    "\n",
    "        _save(filename)\n",
    "\n",
    "        \n",
    "def process_request(response):\n",
    "    \"\"\" Extracts the sentiment and emotion from the response \n",
    "    \n",
    "    This function puts the sentiment and emotion labels and score \n",
    "    into their respective lists. If an error is encountered a filler\n",
    "    message is added.\n",
    "    \n",
    "    Args:\n",
    "        response (JSON): the full JSON response from the API containing\n",
    "            informaiton on the emotion and sentiment of the broadcast data\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    # two variables used as a flag to indicate an error has occurred\n",
    "    sentiment_error = False \n",
    "    emotion_error = False\n",
    "    \n",
    "    '''\n",
    "    Call helper function _key exists to check if the response has the\n",
    "    appropriate keys before we access them. Sanity Check\n",
    "    ''' \n",
    "    \n",
    "    if _key_exists(response, 'sentiment'):\n",
    "        if _key_exists(response['sentiment'], 'targets'):\n",
    "            score = response['sentiment']['targets'][0]['score']\n",
    "            label = response['sentiment']['targets'][0]['label']\n",
    "\n",
    "            sentiment_score.append(score)\n",
    "            sentiment_label.append(label)\n",
    "\n",
    "        else:\n",
    "            sentiment_error = True\n",
    "\n",
    "    else:\n",
    "        sentiment_error = True\n",
    "\n",
    "    if _key_exists(response, 'emotion'):\n",
    "        if _key_exists(response['emotion'], 'targets'):\n",
    "            emotions = response['emotion']['targets'][0]['emotion']\n",
    "            \n",
    "            label, score = [], []\n",
    "            \n",
    "            for em_label, value in emotions.items():\n",
    "                label.append(em_label)\n",
    "                score.append(value)\n",
    "            \n",
    "            \n",
    "            label = ' '.join(label) # join the emotion labels together in a string\n",
    "        \n",
    "            emotion_score.append(score)\n",
    "            emotion_label.append(label)\n",
    "\n",
    "        else:\n",
    "            emotion_error = True\n",
    "\n",
    "    else:\n",
    "        emotion_error = True\n",
    "    \n",
    "    # if an error has occurred we add a filler error message\n",
    "    if sentiment_error:\n",
    "        sentiment_label.append('Sentiment not retrieved for this text')\n",
    "        sentiment_score.append(np.inf)\n",
    "\n",
    "    if emotion_error:\n",
    "        emotion_label.append('Emotion not retrieved for this text')\n",
    "        emotion_score.append(np.inf)\n",
    "\n",
    "def _key_exists(data, key):\n",
    "    \"\"\" This function checks if key exists in data\n",
    "    \n",
    "    Args:\n",
    "        data: dict that we are checking if key exists \n",
    "        key: variable to check if it exists in data\n",
    "    \n",
    "    Returns: True or False if the key exists or not\n",
    "    \"\"\"\n",
    "    \n",
    "    if key in data.keys():\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def save(filename=None):\n",
    "    \"\"\" Saves the items in the lists to a file\n",
    "    \n",
    "    Args:\n",
    "        filename\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with open(f'{filename}.txt', 'w') as filehandle:\n",
    "        filehandle.writelines(\"%s\\n\" % (\"Emotion Label, Emotion Score, Sentence Label, Sentence Score\"))\n",
    "        for em_label, em_score, sent_label, sent_score in zip(emotion_label, emotion_score, sentiment_label, sentiment_score):\n",
    "            filehandle.writelines(\"%s, %s, %s, %s\\n\" % (em_label, em_score, sent_label, sent_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas(desc=f\"Processesing Each File\", position=1, leave=False)\n",
    "\n",
    "queries = [q1, q2, q3, q4, q5]\n",
    "for index, q in enumerate(tqdm(queries, position=0, leave=True, desc='Files Completed')):\n",
    "    file_name = index\n",
    "    q.head().progress_apply(lambda x: make_request(x), axis=1)\n",
    "    save(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
