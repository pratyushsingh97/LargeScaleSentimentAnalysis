{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulsar Sentiment Analysis \n",
    "### by: Pratyush Singh & Mike Volpe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook's purpose is to give you an idea how Mike & I approached and solved the problem using NLU on large amounts of data.\n",
    "\n",
    "For more information on the specifics, checkout the blog on this issue: https://w3-connections.ibm.com/blogs/43734abe-b3a7-41c8-96eb-a2b3b96936ab/entry/Handling_Large_Amounts_of_Data_through_NLU_Effective_Data_Processingusing_Python_and_Watson_NLU?lang=en_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import requests\n",
    "import urllib.parse\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### If you want to read in your own data, simply replace the 'Twitter_Broadcast Raw Data...' with your own file_name. <br>\n",
    "- Pandas has the ability to read many other types formats such as CSV's. For the full documentation visit the pandas website\n",
    "\n",
    "- https://pandas.pydata.org/pandas-docs/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the files. Replace with the path to your own file. Visit pandas to learn how to read other files\n",
    "q1 = pd.read_excel('Twitter_Broadcast Raw Data_2.0.xlsx', sheet_name='Query1 - Full Boolean')\n",
    "q2 = pd.read_excel('Twitter_Broadcast Raw Data_2.0.xlsx', sheet_name='Query2 - Financial')\n",
    "q3 = pd.read_excel('Twitter_Broadcast Raw Data_2.0.xlsx', sheet_name='Query3 - Brand & Health')\n",
    "q4 = pd.read_excel('Twitter_Broadcast Raw Data_2.0.xlsx', sheet_name='Query4 - Leadership')\n",
    "q5 = pd.read_excel('Twitter_Broadcast Raw Data_2.0.xlsx', sheet_name='Query5 -  Product (redesign)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Text</th>\n",
       "      <th>Published</th>\n",
       "      <th>Language</th>\n",
       "      <th>Country</th>\n",
       "      <th>FeedInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12362320689</td>\n",
       "      <td>NewsChannel 10 at 6pm</td>\n",
       "      <td>WE ARE TRACKING A SLOW-MOVING FRONT ALMOST DI...</td>\n",
       "      <td>2018-08-19 22:00:00</td>\n",
       "      <td>English</td>\n",
       "      <td>US</td>\n",
       "      <td>{\"Url\"=&gt;\"http://wsls.com/\", \"ExtKey\"=&gt;\"34edb91...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>12363483953</td>\n",
       "      <td>WSLS 10 Today</td>\n",
       "      <td>pp REMEMBERING A TODDLER.  THE FAMILY OF A 22...</td>\n",
       "      <td>2018-08-20 10:00:00</td>\n",
       "      <td>English</td>\n",
       "      <td>US</td>\n",
       "      <td>{\"Url\"=&gt;\"http://wsls.com/\", \"ExtKey\"=&gt;\"34edb91...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>14334637144</td>\n",
       "      <td>ESPNU 7PM</td>\n",
       "      <td>STEVE: LUDMAN, HE DIDN'T LIKE THAT.  THAT WAS...</td>\n",
       "      <td>2018-08-22 00:00:00</td>\n",
       "      <td>English</td>\n",
       "      <td>US</td>\n",
       "      <td>{\"Url\"=&gt;\"http://espn.go.com/college-sports/\", ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13886480650</td>\n",
       "      <td>Newsroom Tokyo</td>\n",
       "      <td>FAR BELOW THE SURFACE.  &gt;. &gt; ONE OF THE SOUTH...</td>\n",
       "      <td>2018-08-22 11:30:00</td>\n",
       "      <td>English</td>\n",
       "      <td>US</td>\n",
       "      <td>{\"Url\"=&gt;\"http://www.pbs.org/\", \"ExtKey\"=&gt;\"66e9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>14336805720</td>\n",
       "      <td>Dan Le Batard Show10AM</td>\n",
       "      <td>DOWN.  TWO PITCHES, TWO OUTS.  BROCK: TWO DOW...</td>\n",
       "      <td>2018-08-22 15:00:00</td>\n",
       "      <td>English</td>\n",
       "      <td>US</td>\n",
       "      <td>{\"Url\"=&gt;\"http://espn.go.com/college-sports/\", ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id                 Subject  \\\n",
       "0  12362320689   NewsChannel 10 at 6pm   \n",
       "1  12363483953           WSLS 10 Today   \n",
       "2  14334637144               ESPNU 7PM   \n",
       "3  13886480650          Newsroom Tokyo   \n",
       "4  14336805720  Dan Le Batard Show10AM   \n",
       "\n",
       "                                                Text           Published  \\\n",
       "0   WE ARE TRACKING A SLOW-MOVING FRONT ALMOST DI... 2018-08-19 22:00:00   \n",
       "1   pp REMEMBERING A TODDLER.  THE FAMILY OF A 22... 2018-08-20 10:00:00   \n",
       "2   STEVE: LUDMAN, HE DIDN'T LIKE THAT.  THAT WAS... 2018-08-22 00:00:00   \n",
       "3   FAR BELOW THE SURFACE.  >. > ONE OF THE SOUTH... 2018-08-22 11:30:00   \n",
       "4   DOWN.  TWO PITCHES, TWO OUTS.  BROCK: TWO DOW... 2018-08-22 15:00:00   \n",
       "\n",
       "  Language Country                                           FeedInfo  \n",
       "0  English      US  {\"Url\"=>\"http://wsls.com/\", \"ExtKey\"=>\"34edb91...  \n",
       "1  English      US  {\"Url\"=>\"http://wsls.com/\", \"ExtKey\"=>\"34edb91...  \n",
       "2  English      US  {\"Url\"=>\"http://espn.go.com/college-sports/\", ...  \n",
       "3  English      US  {\"Url\"=>\"http://www.pbs.org/\", \"ExtKey\"=>\"66e9...  \n",
       "4  English      US  {\"Url\"=>\"http://espn.go.com/college-sports/\", ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_score, sentiment_label = [], []\n",
    "emotion_score, emotion_label = [], []\n",
    "file_name = None\n",
    "\n",
    "def make_request(row):\n",
    "    \"\"\" This function makes retrieves emotion and sentiment for twitter\n",
    "    \n",
    "    The function makes a call to Watson NLU to retrieve targeted sentiment and\n",
    "    emotion for the word twitter. After the results are retrieved it calls \n",
    "    'process_request' to handle the post-processesing of the json response.\n",
    "    \n",
    "    Args:\n",
    "        - row: the row of data\n",
    "    \n",
    "    Returns: None\n",
    "    \n",
    "    \"\"\"\n",
    "    text = row.Text # replace \"Text\" with the name of the column you wish to analyze\n",
    "    index = row.name\n",
    "    \n",
    "    if not index % 10:\n",
    "        save(file_name)\n",
    "    \n",
    "    # some pre-processesing of the text such as lower-casing and removing punctuation\n",
    "    text = text.strip().lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = str(text)\n",
    "    \n",
    "    try:\n",
    "        if 'twitter' in text:\n",
    "            \n",
    "            # make the actual request to the api with the proper headers\n",
    "            headers = {'Content-Type': 'application/json',}\n",
    "            params = (\n",
    "                    ('text', text),\n",
    "                    ('features','emotion,sentiment'),\n",
    "                    ('entities.emotion', 'true'),\n",
    "                    ('entities.sentiment', 'true'),\n",
    "                    ('emotion.targets', 'twitter'),\n",
    "                    ('sentiment.targets', 'twitter'),\n",
    "                )\n",
    "\n",
    "            response = requests.get(\"https://gateway.watsonplatform.net/natural-language-understanding/api/v1/analyze?version=2019-07-12\", \n",
    "                                     headers=headers, \n",
    "                                     params=params,\n",
    "                                     auth=('apikey', API_KEY))\n",
    "            \n",
    "            response = json.loads(response.text)\n",
    "            \n",
    "            process_request(response)\n",
    "\n",
    "        else:\n",
    "            # if twitter is not in the text, then add this placeholder text to the list\n",
    "            sentiment_label.append('Twitter not in text')\n",
    "            sentiment_score.append(np.inf) \n",
    "\n",
    "            emotion_label.append('Twitter not in text')\n",
    "            emotion_score.append(np.inf)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        # in the case of a keyboard interrupt, save the file and exit the program\n",
    "        print(\"Saving your progress...\")\n",
    "        _save(filename)\n",
    "        \n",
    "        sys.exit()\n",
    "\n",
    "    except Exception as e:\n",
    "        # if any exception has occurred then we add in a filler message\n",
    "        sentiment_label.append(e)\n",
    "        emotion_label.append(e)\n",
    "\n",
    "        sentiment_score.append(np.inf)\n",
    "        emotion_score.append(np.inf)\n",
    "\n",
    "        _save(filename)\n",
    "\n",
    "        \n",
    "def process_request(response):\n",
    "    \"\"\" Extracts the sentiment and emotion from the response \n",
    "    \n",
    "    This function puts the sentiment and emotion labels and score \n",
    "    into their respective lists. If an error is encountered a filler\n",
    "    message is added.\n",
    "    \n",
    "    Args:\n",
    "        response (JSON): the full JSON response from the API containing\n",
    "            informaiton on the emotion and sentiment of the broadcast data\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    # two variables used as a flag to indicate an error has occurred\n",
    "    sentiment_error = False \n",
    "    emotion_error = False\n",
    "    \n",
    "    '''\n",
    "    Call helper function _key exists to check if the response has the\n",
    "    appropriate keys before we access them. Sanity Check\n",
    "    ''' \n",
    "    \n",
    "    if _key_exists(response, 'sentiment'):\n",
    "        if _key_exists(response['sentiment'], 'targets'):\n",
    "            score = response['sentiment']['targets'][0]['score']\n",
    "            label = response['sentiment']['targets'][0]['label']\n",
    "\n",
    "            sentiment_score.append(score)\n",
    "            sentiment_label.append(label)\n",
    "\n",
    "        else:\n",
    "            sentiment_error = True\n",
    "\n",
    "    else:\n",
    "        sentiment_error = True\n",
    "\n",
    "    if _key_exists(response, 'emotion'):\n",
    "        if _key_exists(response['emotion'], 'targets'):\n",
    "            emotions = response['emotion']['targets'][0]['emotion']\n",
    "            \n",
    "            label, score = [], []\n",
    "            \n",
    "            for em_label, value in emotions.items():\n",
    "                label.append(em_label)\n",
    "                score.append(value)\n",
    "            \n",
    "            \n",
    "            label = ' '.join(label) # join the emotion labels together in a string\n",
    "        \n",
    "            emotion_score.append(score)\n",
    "            emotion_label.append(label)\n",
    "\n",
    "        else:\n",
    "            emotion_error = True\n",
    "\n",
    "    else:\n",
    "        emotion_error = True\n",
    "    \n",
    "    # if an error has occurred we add a filler error message\n",
    "    if sentiment_error:\n",
    "        sentiment_label.append('Sentiment not retrieved for this text')\n",
    "        sentiment_score.append(np.inf)\n",
    "\n",
    "    if emotion_error:\n",
    "        emotion_label.append('Emotion not retrieved for this text')\n",
    "        emotion_score.append(np.inf)\n",
    "\n",
    "def _key_exists(data, key):\n",
    "    \"\"\" This function checks if key exists in data\n",
    "    \n",
    "    Args:\n",
    "        data: dict that we are checking if key exists \n",
    "        key: variable to check if it exists in data\n",
    "    \n",
    "    Returns: True or False if the key exists or not\n",
    "    \"\"\"\n",
    "    \n",
    "    if key in data.keys():\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def save(filename=None):\n",
    "    \"\"\" Saves the items in the lists to a file\n",
    "    \n",
    "    Args:\n",
    "        filename\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with open(f'{filename}.txt', 'w') as filehandle:\n",
    "        filehandle.writelines(\"%s\\n\" % (\"Emotion Label, Emotion Score, Sentence Label, Sentence Score\"))\n",
    "        for em_label, em_score, sent_label, sent_score in zip(emotion_label, emotion_score, sentiment_label, sentiment_score):\n",
    "            filehandle.writelines(\"%s, %s, %s, %s\\n\" % (em_label, em_score, sent_label, sent_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas(desc=f\"Processesing Each File\", position=1, leave=False)\n",
    "\n",
    "queries = [q1, q2, q3, q4, q5]\n",
    "for index, q in enumerate(tqdm(queries, position=0, leave=True, desc='Files Completed')):\n",
    "    file_name = index\n",
    "    q.head().progress_apply(lambda x: make_request(x), axis=1)\n",
    "    save(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
